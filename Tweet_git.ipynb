{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import string\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates where targets are not confusing\n",
    "train = train.drop_duplicates(subset = ['text', 'target'])\n",
    "# Now, we have only duplicates with different values of target variable for the same message. Drop all of them\n",
    "rep = pd.concat(x for _, x in train.groupby('text') if len(x) > 1)\n",
    "lst = [rep.loc[i, 'id'] for i in rep.index]\n",
    "train = train[~train.id.isin(lst)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text'] = train['text'].str.lower()\n",
    "test['text'] = test['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do lemmatization \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "for i in train.index:\n",
    "    train.loc[i, 'text'] = str([lemmatizer.lemmatize(w, pos = 'v') for w in nltk.word_tokenize(train.text[i])])\n",
    "for i in test.index:\n",
    "    test.loc[i, 'text'] = str([lemmatizer.lemmatize(w, pos = 'v') for w in nltk.word_tokenize(test.text[i])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\b(?:the|a|an|or|and)\\\\b'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove StopWords\n",
    "words = ['the', 'a', 'an', 'or', 'and']\n",
    "pat = r'\\b(?:{})\\b'.format('|'.join(words))\n",
    "\n",
    "train['text'] = train['text'].str.replace(pat, '', regex = True)\n",
    "test['text'] = test['text'].str.replace(pat, '', regex = True)\n",
    "train['text'] = train['text'].apply(lambda x: re.sub(r'(\\d+),(\\d+)', r'\\1\\2', x))\n",
    "test['text'] = test['text'].apply(lambda x: re.sub(r'(\\d+),(\\d+)', r'\\1\\2', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove punctuation except exclamation and question marks\n",
    "c = set(string.punctuation)\n",
    "p_to_exclude = ['?', '!']\n",
    "c = c.difference(p_to_exclude)\n",
    "train.text = train.text.replace(r'[{}]'.format(re.escape(''.join(c))), '', regex=True)\n",
    "test.text = test.text.replace(r'[{}]'.format(re.escape(''.join(c))), '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    4297\n",
      "1    3188\n",
      "Name: id, dtype: int64\n",
      "57.0 : 43.0\n"
     ]
    }
   ],
   "source": [
    "# Classes are slightly imbalanced\n",
    "print(train.groupby('target').id.count())\n",
    "print(round(train.groupby('target').id.count()[0] / train.id.count() * 100, 0) , ':', round(train.groupby('target').id.count()[1] / train.id.count() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do vectorization \n",
    "vectorizer = TfidfVectorizer()\n",
    "train_vectors = vectorizer.fit_transform(train['text'])\n",
    "test_vectors = vectorizer.transform(test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_vectors, train.target, test_size = 0.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SVM ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel = 'linear') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.77184466, 0.74189676, 0.72952854, 0.72243346, 0.72590738])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(clf, X_train, y_train, cv = 5, scoring= 'f1')\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8076580587711487\n",
      "Precision: 0.837730870712401\n",
      "Recall: 0.6726694915254238\n",
      "F1: 0.7461809635722679\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "print(\"F1:\",metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv('sample_submission.csv')\n",
    "sample_submission[\"target\"] = clf.predict(test_vectors)\n",
    "sample_submission.to_csv(\"submission191.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL SCORE 0.79650"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
