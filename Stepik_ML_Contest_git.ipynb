{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import numpy as np\n",
    "from sklearn import svm\n",
    "import xgboost as xg\n",
    "from numpy import mean\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import *\n",
    "from scipy.stats import uniform, randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_train = pd.read_csv('event_data_train.csv') # all steps data\n",
    "sub_train = pd.read_csv('submissions_data_train.csv') # exercising steps data\n",
    "ev_test = pd.read_csv('events_data_test.csv')\n",
    "sub_test = pd.read_csv('submission_data_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create trget variable\n",
    "ev_train['result'] = ev_train[ev_train.action == 'passed'].groupby('user_id').step_id.transform('nunique')\n",
    "ev_train['result'] = np.where((ev_train['result'] >= 80), 1, 0)\n",
    "ev_train['result'] = ev_train.groupby('user_id').result.transform('max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result\n",
      "0    1123099\n",
      "1    2357604\n",
      "Name: user_id, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4763730465336842"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the class balance for result variable\n",
    "print(ev_train.groupby('result').user_id.count())\n",
    "sns.catplot(x = 'result', kind = 'count', palette = 'PiYG', data = ev_train);\n",
    "# We may see that classes are imbalanced\n",
    "imb = ev_train.groupby('result').user_id.count()[0] / ev_train.groupby('result').user_id.count()[1]\n",
    "imb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[step_id       int64\n",
       " timestamp     int64\n",
       " action       object\n",
       " user_id       int64\n",
       " result        int32\n",
       " dtype: object,\n",
       " step_id       int64\n",
       " timestamp     int64\n",
       " action       object\n",
       " user_id       int64\n",
       " dtype: object,\n",
       " step_id               int64\n",
       " timestamp             int64\n",
       " submission_status    object\n",
       " user_id               int64\n",
       " dtype: object,\n",
       " step_id               int64\n",
       " timestamp             int64\n",
       " submission_status    object\n",
       " user_id               int64\n",
       " dtype: object]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df.dtypes for df in (ev_train, ev_test, sub_train, sub_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, False]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df.isnull().values.any() for df in (ev_train, ev_test, sub_train, sub_test)] # there are no missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_train['date'] = [d.date() for d in pd.to_datetime(ev_train['timestamp'], unit = 's')]\n",
    "ev_test['date'] = [d.date() for d in pd.to_datetime(ev_test['timestamp'], unit = 's')]\n",
    "sub_train['date'] = [d.date() for d in pd.to_datetime(sub_train['timestamp'], unit = 's')]\n",
    "sub_test['date'] = [d.date() for d in pd.to_datetime(sub_test['timestamp'], unit = 's')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev_train['first_d'] = ev_train.groupby('user_id').date.transform('min')\n",
    "m = ev_train.date <= pd.DatetimeIndex(ev_train.first_d) + DateOffset(days = 2)\n",
    "ev_train = ev_train.loc[m]\n",
    "#############################\n",
    "sub_train['first_d'] = sub_train['user_id'].map(ev_train['first_d'])\n",
    "m1 = sub_train.date <= pd.DatetimeIndex(sub_train.first_d) + DateOffset(days = 2)\n",
    "sub_train = sub_train.loc[m1]\n",
    "##################################\n",
    "ev_test['first_d'] = ev_test.groupby('user_id').date.transform('min')\n",
    "#############################\n",
    "sub_test['first_d'] = sub_test['user_id'].map(ev_test['first_d']).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step_unique, step_passed, activity at the start of learning (0 day), activity on the first day, activity \n",
    "# on the second day\n",
    "ev_train['step_unique'] = ev_train.groupby('user_id').step_id.transform('nunique')\n",
    "ev_train['step_passed'] = ev_train[ev_train.action == 'passed'].groupby('user_id').step_id.transform('nunique')\n",
    "ev_train['step_passed_0d'] = ev_train[(ev_train.action == 'passed') & (ev_train.date == ev_train.first_d)].groupby('user_id').step_id.transform('nunique')\n",
    "ev_train['step_passed_1std'] = ev_train[(ev_train.action == 'passed') & (pd.DatetimeIndex(ev_train.date) - pd.DatetimeIndex(ev_train.first_d) == '1 days')].groupby('user_id').step_id.transform('nunique')\n",
    "ev_train['step_passed_2nd'] = ev_train[(ev_train.action == 'passed') & (pd.DatetimeIndex(ev_train.date) - pd.DatetimeIndex(ev_train.first_d) == '2 days')].groupby('user_id').step_id.transform('nunique')\n",
    "\n",
    "# result (it was said that the threshold is 40)\n",
    "#ev_train['result'] = 0\n",
    "#ev_train.loc[ev_train['step_passed'] >= 40, 'result'] = 1\n",
    "# replace Nan with 0 steps:\n",
    "ev_train = ev_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the same for ev_test\n",
    "ev_test['step_unique'] = ev_test.groupby('user_id').step_id.transform('nunique')\n",
    "ev_test['step_passed'] = ev_test[ev_test.action == 'passed'].groupby('user_id').step_id.transform('nunique')\n",
    "ev_test['step_passed_0d'] = ev_test[(ev_test.action == 'passed') & (ev_test.date == ev_test.first_d)].groupby('user_id').step_id.transform('nunique')\n",
    "ev_test['step_passed_1std'] = ev_test[(ev_test.action == 'passed') & (pd.DatetimeIndex(ev_test.date) - pd.DatetimeIndex(ev_test.first_d) == '1 days')].groupby('user_id').step_id.transform('nunique')\n",
    "ev_test['step_passed_2nd'] = ev_test[(ev_test.action == 'passed') & (pd.DatetimeIndex(ev_test.date) - pd.DatetimeIndex(ev_test.first_d) == '2 days')].groupby('user_id').step_id.transform('nunique')\n",
    "\n",
    "# result (it was said that the threshold is 40)\n",
    "ev_test['result'] = 0\n",
    "ev_test.loc[ev_test['step_passed'] >= 40, 'result'] = 1\n",
    "# replace Nan with 0 steps:\n",
    "ev_test = ev_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task unique, tasks_correct, 0 day tasks_correct, 1st day tasks_correct, 2 nd day tasks_correct\n",
    "sub_train['tasks_unique'] = sub_train.groupby('user_id').step_id.transform('nunique')\n",
    "sub_train['tasks_correct'] = sub_train[sub_train.submission_status == 'correct'].groupby('user_id').step_id.transform('nunique')\n",
    "sub_train['tasks_correct_0st'] = sub_train[(sub_train.submission_status == 'correct') & (sub_train.date == sub_train.first_d)].groupby('user_id').step_id.transform('nunique')\n",
    "sub_train['tasks_correct_1st'] = sub_train[(sub_train.submission_status == 'correct') & (pd.DatetimeIndex(sub_train.date) - pd.DatetimeIndex(sub_train.first_d) == '1 days')].groupby('user_id').step_id.transform('nunique')\n",
    "sub_train['tasks_correct_2nd'] = sub_train[(sub_train.submission_status == 'correct') & (pd.DatetimeIndex(sub_train.date) - pd.DatetimeIndex(sub_train.first_d) == '2 days')].groupby('user_id').step_id.transform('nunique')\n",
    "\n",
    "# find the number of solving task attempts \n",
    "sub_train['tasks_attempts'] = sub_train.groupby(['user_id', 'step_id']).submission_status.transform('count')\n",
    "# replace Nan with 0:\n",
    "sub_train = sub_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the same for esub_test\n",
    "sub_test['tasks_unique'] = sub_test.groupby('user_id').step_id.transform('nunique')\n",
    "sub_test['tasks_correct'] = sub_test[sub_test.submission_status == 'correct'].groupby('user_id').step_id.transform('nunique')\n",
    "sub_test['tasks_correct_0st'] = sub_test[(sub_test.submission_status == 'correct') & (sub_test.date == sub_test.first_d)].groupby('user_id').step_id.transform('nunique')\n",
    "sub_test['tasks_correct_1st'] = sub_test[(sub_test.submission_status == 'correct') & (pd.DatetimeIndex(sub_test.date) - pd.DatetimeIndex(sub_test.first_d) == '1 days')].groupby('user_id').step_id.transform('nunique')\n",
    "sub_test['tasks_correct_2nd'] = sub_test[(sub_test.submission_status == 'correct') & (pd.DatetimeIndex(sub_test.date) - pd.DatetimeIndex(sub_test.first_d) == '2 days')].groupby('user_id').step_id.transform('nunique')\n",
    "\n",
    "# find the number of solving task attempts \n",
    "sub_test['tasks_attempts'] = sub_test.groupby(['user_id', 'step_id']).submission_status.transform('count')\n",
    "# replace Nan with 0:\n",
    "sub_test = sub_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19234\n",
      "871\n",
      "6184\n",
      "2803\n"
     ]
    }
   ],
   "source": [
    "print(len(ev_train.user_id.unique()))\n",
    "print(len(sub_train.user_id.unique()))\n",
    "print(len(ev_test.user_id.unique()))\n",
    "print(len(sub_test.user_id.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([32075, 31981, 32202, 32795, 32810, 33350, 32206, 32796], dtype='int64', name='step_id')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the most difficult tasks\n",
    "diff = sub_train.drop_duplicates(subset = ['user_id', 'step_id'], keep = 'last').groupby('step_id').tasks_attempts.mean().sort_values()\n",
    "# let's suppose that if average amount of attempts are 4 or more, the task is difficult. \n",
    "diff = diff[diff > 3].index\n",
    "diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy variables for solving the most difficalt tasks\n",
    "dummy = []\n",
    "for i in diff: \n",
    "    dummy.append('is_' + str(i))\n",
    "    sub_train['is_' + str(i)] = np.where((sub_train['step_id'] == i) & (sub_train['submission_status'] == 'correct'), 1, 0)\n",
    "for i in diff: \n",
    "    sub_test['is_' + str(i)] = np.where((sub_test['step_id'] == i) & (sub_test['submission_status'] == 'correct'), 1, 0)\n",
    "    \n",
    "for i in dummy: \n",
    "    sub_train.loc[:, i] = sub_train.groupby('user_id')[i].transform('max')\n",
    "    sub_test.loc[:, i] = sub_test.groupby('user_id')[i].transform('max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train['tasks_attempts_total'] = sub_train.groupby(['user_id']).step_id.transform('count')\n",
    "sub_test['tasks_attempts_total'] = sub_test.groupby(['user_id']).step_id.transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10999, 21)\n",
      "(42261, 21)\n"
     ]
    }
   ],
   "source": [
    "print(sub_train.shape)\n",
    "print(sub_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_columns', None)\n",
    "sub_train[['tasks_correct', 'tasks_correct_0st', 'tasks_correct_1st', 'tasks_correct_2nd']] = sub_train.groupby('user_id')[['tasks_correct', 'tasks_correct_0st', 'tasks_correct_1st', 'tasks_correct_2nd']].transform('max')\n",
    "sub_test[['tasks_correct', 'tasks_correct_0st', 'tasks_correct_1st', 'tasks_correct_2nd']] = sub_test.groupby('user_id')[['tasks_correct', 'tasks_correct_0st', 'tasks_correct_1st', 'tasks_correct_2nd']].transform('max')\n",
    "ev_train[['step_passed', 'step_passed_0d', 'step_passed_1std', 'step_passed_2nd']] = ev_train.groupby('user_id')[['step_passed', 'step_passed_0d', 'step_passed_1std', 'step_passed_2nd']].transform('max')\n",
    "ev_test[['step_passed', 'step_passed_0d', 'step_passed_1std', 'step_passed_2nd']] = ev_test.groupby('user_id')[['step_passed', 'step_passed_0d', 'step_passed_1std', 'step_passed_2nd']].transform('max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 =  ev_train[['user_id', 'step_unique', 'step_passed_0d', 'step_passed_1std', 'step_passed_2nd', 'result']].drop_duplicates(subset = ['user_id'], keep = 'last')\n",
    "test_1 = ev_test[['user_id', 'step_unique', 'step_passed_0d', 'step_passed_1std', 'step_passed_2nd', 'result']].drop_duplicates(subset = ['user_id'], keep = 'last')\n",
    "train_2 =  sub_train[['user_id', 'tasks_unique', 'tasks_correct_1st', 'tasks_correct_2nd', 'tasks_attempts', 'is_32075', 'is_31981', 'is_32202', 'is_32795', 'is_32810', 'is_33350', 'is_32206', 'is_32796']].drop_duplicates(subset = ['user_id'], keep = 'last')\n",
    "test_2 = sub_test[['user_id', 'tasks_unique', 'tasks_correct_1st', 'tasks_correct_2nd', 'tasks_attempts', 'is_32075', 'is_31981', 'is_32202', 'is_32795', 'is_32810', 'is_33350', 'is_32206', 'is_32796']].drop_duplicates(subset = ['user_id'], keep = 'last')\n",
    "train = pd.merge(train_1, train_2, how = 'left')\n",
    "train = train.fillna(0)\n",
    "test = pd.merge(test_1, test_2, how = 'left')\n",
    "test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.result\n",
    "X_train = train.drop('result', 1)\n",
    "y_test = test.result\n",
    "X_test = test.drop('result', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6184, 17)\n",
      "(19234, 17)\n",
      "(6184,)\n",
      "(19234,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xg = xg.XGBClassifier(objective = 'binary:logistic', eval_metric = 'auc', use_label_encoder = False)\n",
    "params = {'n_estimators': randint(100, 500),\n",
    "              'eta': uniform(0.01, 0.6),\n",
    "              'subsample': uniform(0.3, 0.9),\n",
    "              'max_depth': randint(2, 10),\n",
    "              'colsample_bytree': uniform(0.5, 0.9),\n",
    "              'min_child_weight': randint(1,5),\n",
    "              'scale_pos_weight': [imb, 1],\n",
    "              'gamma': uniform(0, 0.9)\n",
    "             }\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "clf = RandomizedSearchCV(clf_xg, \n",
    "                         param_distributions = params,\n",
    "                         cv = kfold,  \n",
    "                         n_iter = 50,\n",
    "                         scoring = 'roc_auc', \n",
    "                         error_score = 0, \n",
    "                         verbose = 3, \n",
    "                         n_jobs = -1,\n",
    "                        refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 50 candidates, totalling 500 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=KFold(n_splits=10, random_state=None, shuffle=True),\n",
       "                   error_score=0,\n",
       "                   estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                           colsample_bylevel=None,\n",
       "                                           colsample_bynode=None,\n",
       "                                           colsample_bytree=None,\n",
       "                                           eval_metric='auc', gamma=None,\n",
       "                                           gpu_id=None, importance_type='gain',\n",
       "                                           interaction_constraints=None,\n",
       "                                           learning_rate=None,\n",
       "                                           max_delta_step=None, max_depth=No...\n",
       "                                        'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000232B63667C8>,\n",
       "                                        'min_child_weight': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000232A634A208>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000232B6366188>,\n",
       "                                        'scale_pos_weight': [0.4763730465336842,\n",
       "                                                             1],\n",
       "                                        'subsample': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000232B6366888>},\n",
       "                   scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5391  398]\n",
      " [   6  389]]\n",
      "auc:  0.96\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "cm = metrics.confusion_matrix(y_test,y_pred) \n",
    "print(cm)\n",
    "auc_xg = np.round(metrics.roc_auc_score(y_test, y_pred),2)\n",
    "print('auc: ', auc_xg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "ev_test1 = pd.read_csv('events_data_test_1.csv')\n",
    "sub_test1 = pd.read_csv('submission_data_test_1.csv')\n",
    "ev_test1['date'] = [d.date() for d in pd.to_datetime(ev_test1['timestamp'], unit = 's')]\n",
    "sub_test1['date'] = [d.date() for d in pd.to_datetime(sub_test1['timestamp'], unit = 's')]\n",
    "ev_test1['first_d'] = ev_test1.groupby('user_id').date.transform('min')\n",
    "sub_test1['first_d'] = sub_test1['user_id'].map(ev_test1['first_d']).copy()\n",
    "ev_test1['step_unique'] = ev_test1.groupby('user_id').step_id.transform('nunique')\n",
    "ev_test1['step_passed'] = ev_test1[ev_test1.action == 'passed'].groupby('user_id').step_id.transform('nunique')\n",
    "ev_test1['step_passed_0d'] = ev_test1[(ev_test1.action == 'passed') & (ev_test1.date == ev_test1.first_d)].groupby('user_id').step_id.transform('nunique')\n",
    "ev_test1['step_passed_1std'] = ev_test1[(ev_test1.action == 'passed') & (pd.DatetimeIndex(ev_test1.date) - pd.DatetimeIndex(ev_test1.first_d) == '1 days')].groupby('user_id').step_id.transform('nunique')\n",
    "ev_test1['step_passed_2nd'] = ev_test1[(ev_test1.action == 'passed') & (pd.DatetimeIndex(ev_test1.date) - pd.DatetimeIndex(ev_test1.first_d) == '2 days')].groupby('user_id').step_id.transform('nunique')\n",
    "\n",
    "# result (it was said that the threshold is 40)\n",
    "ev_test1['result'] = 0\n",
    "ev_test1.loc[ev_test1['step_passed'] >= 40, 'result'] = 1\n",
    "# replace Nan with 0 steps:\n",
    "ev_test1 = ev_test1.fillna(0)\n",
    "sub_test1['tasks_unique'] = sub_test1.groupby('user_id').step_id.transform('nunique')\n",
    "sub_test1['tasks_correct'] = sub_test1[sub_test1.submission_status == 'correct'].groupby('user_id').step_id.transform('nunique')\n",
    "sub_test1['tasks_correct_0st'] = sub_test1[(sub_test1.submission_status == 'correct') & (sub_test1.date == sub_test1.first_d)].groupby('user_id').step_id.transform('nunique')\n",
    "sub_test1['tasks_correct_1st'] = sub_test1[(sub_test1.submission_status == 'correct') & (pd.DatetimeIndex(sub_test1.date) - pd.DatetimeIndex(sub_test1.first_d) == '1 days')].groupby('user_id').step_id.transform('nunique')\n",
    "sub_test1['tasks_correct_2nd'] = sub_test1[(sub_test1.submission_status == 'correct') & (pd.DatetimeIndex(sub_test1.date) - pd.DatetimeIndex(sub_test1.first_d) == '2 days')].groupby('user_id').step_id.transform('nunique')\n",
    "\n",
    "# find the number of solving task attempts \n",
    "sub_test1['tasks_attempts'] = sub_test1.groupby(['user_id', 'step_id']).submission_status.transform('count')\n",
    "# replace Nan with 0:\n",
    "sub_test1 = sub_test1.fillna(0)\n",
    "\n",
    "for i in diff: \n",
    "    sub_test1['is_' + str(i)] = np.where((sub_test1['step_id'] == i) & (sub_test1['submission_status'] == 'correct'), 1, 0)\n",
    "    \n",
    "for i in dummy: \n",
    "    sub_test1.loc[:, i] = sub_test1.groupby('user_id')[i].transform('max')\n",
    "\n",
    "sub_test1['tasks_attempts_total'] = sub_test1.groupby(['user_id']).step_id.transform('count')\n",
    "\n",
    "sub_test1[['tasks_correct', 'tasks_correct_0st', 'tasks_correct_1st', 'tasks_correct_2nd']] = sub_test1.groupby('user_id')[['tasks_correct', 'tasks_correct_0st', 'tasks_correct_1st', 'tasks_correct_2nd']].transform('max')\n",
    "ev_test1[['step_passed', 'step_passed_0d', 'step_passed_1std', 'step_passed_2nd']] = ev_test1.groupby('user_id')[['step_passed', 'step_passed_0d', 'step_passed_1std', 'step_passed_2nd']].transform('max')\n",
    "test1_1 = ev_test1[['user_id', 'step_unique', 'step_passed_0d', 'step_passed_1std', 'step_passed_2nd', 'result']].drop_duplicates(subset = ['user_id'], keep = 'last')\n",
    "test1_2 = sub_test1[['user_id', 'tasks_unique', 'tasks_correct_1st', 'tasks_correct_2nd', 'tasks_attempts', 'is_32075', 'is_31981', 'is_32202', 'is_32795', 'is_32810', 'is_33350', 'is_32206', 'is_32796']].drop_duplicates(subset = ['user_id'], keep = 'last')\n",
    "\n",
    "test1 = pd.merge(test1_1, test1_2, how = 'left')\n",
    "test1 = test1.fillna(0)\n",
    "\n",
    "y_test1 = test1.result\n",
    "X_test1 = test1.drop('result', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_xg1 = clf.predict(X_test1)\n",
    "prob_xg1 = clf.predict_proba(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = pd.concat([pd.DataFrame(X_test1.user_id), pd.DataFrame(pd.DataFrame(np.round(prob_xg1,2))[1])], axis = 1)\n",
    "output1.columns = ['user_id','is_gone']\n",
    "output = output1.set_index('user_id')\n",
    "output1.to_csv('final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
